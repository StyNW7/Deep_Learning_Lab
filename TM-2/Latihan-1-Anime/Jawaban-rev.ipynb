{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2e4001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import os\n",
    "\n",
    "# --- 1. KONFIGURASI & LOAD DATASET ---\n",
    "# Sesuaikan path ini dengan lokasi folder dataset Anime Anda\n",
    "IMAGE_PATH = \"./data/\" \n",
    "\n",
    "# Parameter sesuai Soal Anime\n",
    "IMAGE_SIZE = 64\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 60       # Minimum 60 epochs sesuai soal\n",
    "LATENT_DIM = 32   # Dimensi latent space\n",
    "LEARNING_RATE = 0.0001 # Learning rate standard untuk CVAE\n",
    "\n",
    "def load_data(path):\n",
    "    images = []\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Error: Path {path} tidak ditemukan.\")\n",
    "        return np.array([])\n",
    "        \n",
    "    # Mengambil list file gambar\n",
    "    files = [f for f in os.listdir(path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    for filename in files:\n",
    "        try:\n",
    "            # Load gambar dan resize ke 64x64\n",
    "            img = tf.keras.preprocessing.image.load_img(\n",
    "                os.path.join(path, filename), \n",
    "                target_size=(IMAGE_SIZE, IMAGE_SIZE)\n",
    "            )\n",
    "            img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "            images.append(img)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "            \n",
    "    return np.array(images)\n",
    "\n",
    "print(\"Loading Anime dataset...\")\n",
    "images = load_data(IMAGE_PATH)\n",
    "print(f\"Jumlah gambar ditemukan: {len(images)}\")\n",
    "\n",
    "# --- 2. DATA PREPROCESSING & SPLIT ---\n",
    "if len(images) > 0:\n",
    "    # Shuffle dataset (Sesuai soal: Randomly shuffle)\n",
    "    np.random.shuffle(images)\n",
    "\n",
    "    # Normalisasi (Membagi dengan 255 -> range 0-1)\n",
    "    images = images.astype('float32') / 255.0\n",
    "    \n",
    "    # NOTE: Tidak di-flatten (reshape ke 1D) karena kita pakai CNN (Conv2D)\n",
    "    # Shape tetap: (Jumlah Data, 64, 64, 3)\n",
    "\n",
    "    # Split Dataset: 80% Train, 10% Validation, 10% Test (Sesuai Soal)\n",
    "    total_data = len(images)\n",
    "    train_count = int(0.8 * total_data)\n",
    "    val_count = int(0.1 * total_data)\n",
    "    # Sisanya untuk test\n",
    "    \n",
    "    x_train = images[:train_count]\n",
    "    x_val = images[train_count : train_count + val_count]\n",
    "    x_test = images[train_count + val_count :]\n",
    "    \n",
    "    print(f\"Training Data   : {x_train.shape}\")\n",
    "    print(f\"Validation Data : {x_val.shape}\")\n",
    "    print(f\"Testing Data    : {x_test.shape}\")\n",
    "\n",
    "    # Buat tf.data.Dataset untuk batching\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\\\n",
    "                    .shuffle(BATCH_SIZE * 5).batch(BATCH_SIZE)\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices(x_val).batch(BATCH_SIZE)\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE)\n",
    "\n",
    "# --- 3. ARSITEKTUR VAE (CONVOLUTIONAL / CVAE) ---\n",
    "# Menggunakan Conv2D karena lebih cocok untuk detail wajah Anime dibanding Dense\n",
    "class CVAE(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # --- ENCODER (CNN) ---\n",
    "        # Input: (64, 64, 3)\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.InputLayer(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)),\n",
    "            \n",
    "            layers.Conv2D(32, 3, strides=2, padding='same', activation='relu', name=\"enc_conv1\"),\n",
    "            layers.BatchNormalization(),\n",
    "            \n",
    "            layers.Conv2D(64, 3, strides=2, padding='same', activation='relu', name=\"enc_conv2\"),\n",
    "            layers.BatchNormalization(),\n",
    "            \n",
    "            layers.Conv2D(128, 3, strides=2, padding='same', activation='relu', name=\"enc_conv3\"),\n",
    "            layers.BatchNormalization(),\n",
    "            \n",
    "            layers.Flatten(),\n",
    "        ], name=\"encoder_net\")\n",
    "        \n",
    "        # Latent Space (Mean & Log Variance)\n",
    "        self.z_mean = layers.Dense(latent_dim, name=\"z_mean\")\n",
    "        self.z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")\n",
    "\n",
    "        # --- DECODER (CNN Transpose) ---\n",
    "        # Kita mulai dari latent -> Dense -> Reshape ke bentuk 3D kecil\n",
    "        self.dec_dense_input = layers.Dense(8 * 8 * 128, activation='relu', name=\"dec_dense\")\n",
    "        self.dec_reshape = layers.Reshape((8, 8, 128), name=\"dec_reshape\")\n",
    "        \n",
    "        self.decoder_net = tf.keras.Sequential([\n",
    "            layers.Conv2DTranspose(128, 3, strides=2, padding='same', activation='relu', name=\"dec_convT1\"),\n",
    "            layers.BatchNormalization(),\n",
    "            \n",
    "            layers.Conv2DTranspose(64, 3, strides=2, padding='same', activation='relu', name=\"dec_convT2\"),\n",
    "            layers.BatchNormalization(),\n",
    "            \n",
    "            layers.Conv2DTranspose(32, 3, strides=2, padding='same', activation='relu', name=\"dec_convT3\"),\n",
    "            layers.BatchNormalization(),\n",
    "            \n",
    "            # Output Layer: Sigmoid agar output di range [0, 1]\n",
    "            layers.Conv2DTranspose(3, 3, strides=1, padding='same', activation='sigmoid', name=\"output_layer\") \n",
    "        ], name=\"decoder_net\")\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mean = self.z_mean(h)\n",
    "        log_var = self.z_log_var(h)\n",
    "        return mean, log_var\n",
    "\n",
    "    def reparameterize(self, mean, log_var):\n",
    "        batch = tf.shape(mean)[0]\n",
    "        dim = tf.shape(mean)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch, dim))\n",
    "        return mean + tf.exp(0.5 * log_var) * epsilon\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = self.dec_dense_input(z)\n",
    "        h = self.dec_reshape(h)\n",
    "        logits = self.decoder_net(h)\n",
    "        return logits\n",
    "\n",
    "    def call(self, inputs):\n",
    "        mean, log_var = self.encode(inputs)\n",
    "        z = self.reparameterize(mean, log_var)\n",
    "        reconstruction = self.decode(z)\n",
    "        return reconstruction, mean, log_var\n",
    "\n",
    "# --- 4. TRAINING SETUP ---\n",
    "vae = CVAE(latent_dim=LATENT_DIM)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "# Fungsi Loss\n",
    "def vae_loss_func(y_true, y_pred, mean, log_var):\n",
    "    # 1. Reconstruction Loss\n",
    "    # Karena output sigmoid (pixel 0-1), kita gunakan Binary Crossentropy\n",
    "    recon_loss = tf.reduce_mean(\n",
    "        tf.reduce_sum(\n",
    "            tf.keras.losses.binary_crossentropy(y_true, y_pred), axis=(1, 2)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # 2. KL Divergence\n",
    "    kl_loss = -0.5 * (1 + log_var - tf.square(mean) - tf.exp(log_var))\n",
    "    kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "    \n",
    "    return recon_loss + kl_loss, recon_loss, kl_loss\n",
    "\n",
    "# Step Training\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    with tf.GradientTape() as tape:\n",
    "        reconstruction, mean, log_var = vae(images)\n",
    "        total_loss, recon_loss, kl_loss = vae_loss_func(images, reconstruction, mean, log_var)\n",
    "    \n",
    "    grads = tape.gradient(total_loss, vae.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, vae.trainable_variables))\n",
    "    return total_loss, recon_loss, kl_loss\n",
    "\n",
    "# Step Validation\n",
    "@tf.function\n",
    "def val_step(images):\n",
    "    reconstruction, mean, log_var = vae(images)\n",
    "    total_loss, recon_loss, kl_loss = vae_loss_func(images, reconstruction, mean, log_var)\n",
    "    return total_loss, recon_loss, kl_loss\n",
    "\n",
    "# --- 5. TRAINING LOOP ---\n",
    "if len(images) > 0:\n",
    "    train_loss_hist = []\n",
    "    val_loss_hist = []\n",
    "    \n",
    "    print(f\"\\n--- Starting Training for {EPOCHS} Epochs ---\")\n",
    "    for epoch in range(EPOCHS):\n",
    "        # -- Training Phase --\n",
    "        total_loss_t = 0\n",
    "        steps_t = 0\n",
    "        for batch_imgs in train_dataset:\n",
    "            t_loss, _, _ = train_step(batch_imgs)\n",
    "            total_loss_t += t_loss\n",
    "            steps_t += 1\n",
    "        avg_train_loss = total_loss_t / steps_t\n",
    "        train_loss_hist.append(avg_train_loss)\n",
    "        \n",
    "        # -- Validation Phase --\n",
    "        total_loss_v = 0\n",
    "        steps_v = 0\n",
    "        for batch_imgs in val_dataset:\n",
    "            v_loss, _, _ = val_step(batch_imgs)\n",
    "            total_loss_v += v_loss\n",
    "            steps_v += 1\n",
    "        avg_val_loss = total_loss_v / steps_v if steps_v > 0 else 0\n",
    "        val_loss_hist.append(avg_val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {avg_train_loss:.2f} | Val Loss: {avg_val_loss:.2f}\")\n",
    "\n",
    "    # Plot Loss History\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_loss_hist, label='Training Loss')\n",
    "    plt.plot(val_loss_hist, label='Validation Loss')\n",
    "    plt.title(\"Training vs Validation Loss History\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # --- 6. PREDICTION & EVALUATION ---\n",
    "    # Ambil 10 gambar dari test set untuk visualisasi\n",
    "    test_batch = next(iter(test_dataset))\n",
    "    test_samples = test_batch[:10]\n",
    "    \n",
    "    # Prediksi\n",
    "    recon_images, _, _ = vae(test_samples)\n",
    "    recon_images = recon_images.numpy()\n",
    "    \n",
    "    print(\"\\nVisualisasi Hasil (Original vs Reconstructed):\")\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(10):\n",
    "        # Original\n",
    "        ax = plt.subplot(2, 10, i + 1)\n",
    "        plt.imshow(test_samples[i])\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        # Reconstructed\n",
    "        ax = plt.subplot(2, 10, i + 1 + 10)\n",
    "        plt.imshow(recon_images[i])\n",
    "        plt.title(\"Recon\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Dataset kosong. Pastikan path folder benar.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
